---
header-includes:
- \usepackage[american,spanish,mexico]{babel}
- \usepackage{adjustbox,mathtools,amsmath,caption,geometry,xfrac,placeins,subfig}
- \usepackage{listings}
- \providecommand{\P}{\mathbb{P}}
- \providecommand{\N}{\mathbb{N}}
- \providecommand{\E}{\mathbb{E}}

output:
  pdf_document:
    #pandoc_args: --listings
keep_tex: yes
includes:
      in_header: preamble.tex
fontsize: 11pt
urlcolor: blue
geometry: left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm
---

\lstset{
breaklines=true, basicstyle=\ttfamily
}
\graphicspath{{/Users/angelescalante/Desktop/Inferencia-Bayesiana/proyecto-final}}
\newgeometry{left=1cm,right=2.5cm,top=2.5cm,bottom=2.5cm}
\begin{titlepage} 
	\raggedleft 
	 \raisebox{120ex}{\makebox[2.4cm][l]{\includegraphics[width=3cm]{unam}}}
	 \raisebox{1ex}{\adjustbox{left=-2.571cm}{|}{\makebox[2.5cm][l]{\includegraphics[width=2.5cm]{iimas}}}}
	\rule{1pt}{\textheight}
	\hspace{0.05\textwidth}
	\parbox[b]{0.75\textwidth}{ 
		{\huge\text{Universidad Nacional Aut칩noma de M칠xico}}\\[5\baselineskip]
		{\Huge\bfseries Proyecto Final \\[1.5\baselineskip]}\\[1\baselineskip] 
		{\LARGE\bfseries Inferencia Bayesiana \\[2.25\baselineskip]}\\[1\baselineskip]
		{\LARGE\textsc{ 츼ngel Fernando Escalante L칩pez \\ [0.5\baselineskip] Shadanna Ortega Hern치ndez}}
		
		\vspace{0.30\textheight}
		{\Large\textsc{Dr. Eduardo Guti칠rrez Pe침a}}\\
		\\
		{\large{\noindent Instituto de Investigaciones en Matem치ticas Aplicadas y en Sistemas}}\\[\baselineskip]}
\end{titlepage}

\newgeometry{left=3cm,right=3cm,top=2.5cm,bottom=2.5cm}

\tableofcontents
\clearpage

```{r setup, include=FALSE, echo=FALSE, warning=FALSE}
library(tidyverse)
library(kableExtra)
library(jtools)
library(effects)
library(MASS)
library(vcdExtra)
library(patchwork)
library(rstan)
library(bayesplot)
library(RColorBrewer)
```

# Introducci칩n

En la actualidad, una de las principales causas de muerte es por la enfermedad conocida como c치ncer. El c치ncer comienza en una c칠lula normal que cambia a una c칠lula neopl치sica\footnote{C칠lula con una multiplicaci칩n o crecimiento anormal en un tejido del organismo.} a trav칠s de varias mutaciones en varios genes a lo largo de mucho tiempo, podr칤an ser a침os, de estar expuesto a un agente carcinogen칠tico \footnote{Agente capaz de causar c치ncer.}. No obstante, las mutaciones inducidas por los carcin칩genos no son la 칰nica v칤a que afecta a la c칠lula, sino que a lo largo de cada divisi칩n celular se producen errores espont치neos en cada duplicaci칩n y los mismos se van acumulando constituyendo un factor intr칤nseco de riesgo (Mart칤n de Civetta y Civetta, 2011). Por lo cual, es de suma importancia estudiar la cura para esta enfermedad.

En este contexto, el presente trabajo analizar치 desde una perspectiva bayesiana de un experimento de un tipo de tumor en un grupo de ratas, dadas diferentes dosis de una droga. En otras palabras, estudiar la tasa a la que el riesgo de tumor crece o decrece como funci칩n de la dosis.

Para ello, se examinar치n tres perspectivas de acuerdo al tipo de informaci칩n inicial, despu칠s se har치 la una comparaci칩n entre modelos y por 칰ltimo unos comentarios finales.

# Ejercicio 1:

Con el prop칩sito de estudiar la relaci칩n entre la dosis y la respuesta, se tienen los datos del experimento en el cuadro 1, donde x representa el nivel de la dosis, mientras que $n_x$ y $y_x$ denotan respectivamente, el n칰mero de ratas tratadas y el n칰mero de ratas que presentan tumor en cada nivel $(x=0,1,2)$.

\begin{table}[h]
    \centering
    \begin{tabular}{||c |c |c||}
 \hline
        $x$ & $n_x$ & $y_x$\\[0.5ex] 
 \hline\hline
         0& 14 &4 \\
         \hline
         1& 34 &4 \\
         \hline
         2& 34 &2 \\[1ex] 
 \hline        
    \end{tabular}
    \caption{Datos}
\end{table}


Sea $\pi_x$ la probabilidad de que una rata en el grupo $x$ desarrolle un tumor. Entonces, se considera el modelo 
$$Y_x\thicksim Bin(\pi_x,n_x)\qquad (x=0,1,2).$$

Dado que las investigadoras est치n interesadas en la forma como var칤a $\pi_x$ en funci칩n de la dosis $x$, propusieron el modelo

$$logit(\pi_x)=\alpha+\beta x \qquad (x=0,1,2).$$

El par치metro de inter칠s para las investigadoras es la pendiente $\beta$, pero no cuentan con informaci칩n inicial sobre su valor.

Entonces, se realizar치 un resumen de la distribuci칩n final de $\beta$ suponiendo una distribuci칩n inicial no informativa en la que $\alpha$ y $\beta$ se asumen independientes, con $\alpha \thicksim N(0,1000)$ y $\beta \thicksim N(0,1000)$; esto es, con media 0 y varianza 1000.

\clearpage

## Respuesta

### Definiendo modelo con `Stan`

La declaraci칩n del modelo binomial se hace a trav칠s de la funci칩n `binomial_logit()` de `Stan`, que recibe como segundo par치metro la inversa de la funci칩n logit\footnote{Stan User Guide}, adem치s se usa $\sigma=\sqrt{\sigma^2}= \sqrt{1000}=31.62278$ ya que `Stan` recibe desviaci칩n est치ndar como par치metro y no la varianza.

```{r message=FALSE, warning=FALSE, error=FALSE}
model_string <- 
"
data {
  int<lower=0> N;
  int<lower=0> n[N];
  int<lower=0> y[N];
  vector[N] x;
}

parameters {
  real alpha;
  real beta;
}

model {
  alpha ~ normal(0, 31.62278);
  beta ~ normal(0, 31.62278);
  
  for (i in 1:N) {
    y[i] ~ binomial_logit(n[i], alpha + beta * x[i]);
  }
}
"
```

### Sampleando el modelo con datos del estudio

Para este modelo, se utilizaron los siguientes par치metros en `Stan`:

- N칰mero de iteraciones = 5000
- Warmup (calentamiento) = 2000
- Thin = 3
- N칰mero de cadenas = 4

```{r echo=FALSE, warning=FALSE, message=FALSE, error=FALSE, results=FALSE}
# Datos del experimento
x <- c(0, 1, 2)
n_x <- c(14, 34, 34)
y_x <- c(4, 4, 2)

# Preparar los datos para Stan
data <- list(N = length(x), n = n_x, y = y_x, x = x)

# Compilar el modelo
modelo_1 <- stan_model(model_code = model_string, verbose = FALSE)

# Ajustar el modelo a los datos
fit <- sampling(
  modelo_1,
  data = data,
  iter = 5000,
  warmup = 2000,
  thin = 3,
  chains = 4,
  seed = 123,
  verbose = FALSE,
  open_progress = FALSE
)
```

```{r echo=FALSE}
# Imprimiendo resultados del modelo
print(fit, pars = c("alpha", "beta"))
```

### Diagn칩stico del modelo    

Notamos que el **Rhat** es exactamente 1 para las cadenas de $\alpha$ y $\beta$, lo cu치l representar칤a convergencia para ambos par치metros. Esto se aprecia de igual manera en forma visual a trav칠s de los gr치ficos de las trazas:

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Extraer las muestras de la distribuci칩n posterior
posterior_samples <- extract(fit)
posterior2 <- extract(fit, inc_warmup = TRUE, permuted = FALSE)

color_scheme_set("blue")

# Aqu칤 va un bplot!!! 游뗵
# Usando `posterior_samples$beta`

mcmc_trace(
  posterior2, 
  pars = c("alpha", "beta"),
  n_warmup = 667, 
  facet_args = list(nrow = 2, labeller = label_parsed)
) + theme_minimal() + facet_text(size = 12)

# Calcular los promedios erg칩dicos de las muestras
compute_ergodic_means <- function(samples) {
  cumsum(samples) / seq_along(samples)
}

muestra_promedios_ergodicos <- function(posterior, color_palette = "Blues") {
  alpha_samples <- as.matrix(posterior[, , "alpha"])
  beta_samples <- as.matrix(posterior[, , "beta"])
  
  alpha_ergodic_means <- apply(alpha_samples, 2, compute_ergodic_means)
  
  # Crear un data frame para ggplot2
  iteration <- seq_len(nrow(alpha_ergodic_means))
  df_alpha <- data.frame(iteration, alpha_ergodic_means)
  
  # Graficar los promedios erg칩dicos para alpha
  erg_alpha <- ggplot(df_alpha, aes(x = iteration)) +
    geom_line(aes(y = chain.1, color = "Cadena 1")) +
    geom_line(aes(y = chain.2, color = "Cadena 2")) +
    geom_line(aes(y = chain.3, color = "Cadena 3")) +
    geom_line(aes(y = chain.4, color = "Cadena 4")) +
    labs(title = expression(alpha),
         color = "Cadena",
         y = "") +
    theme_minimal() +
    scale_color_brewer(palette = color_palette) +
    guides(color = "none")
  
  beta_ergodic_means <- apply(beta_samples, 2, compute_ergodic_means)
  df_beta <- data.frame(iteration, beta_ergodic_means)
  
  # Graficar los promedios erg칩dicos para beta
  erg_beta <- ggplot(df_beta, aes(x = iteration)) +
    geom_line(aes(y = chain.1, color = "Cadena 1")) +
    geom_line(aes(y = chain.2, color = "Cadena 2")) +
    geom_line(aes(y = chain.3, color = "Cadena 3")) +
    geom_line(aes(y = chain.4, color = "Cadena 4")) +
    labs(title = expression(beta),
         x = "Iteraci칩n",
         y = "",
         color = "Cadena") +
    theme_minimal() +
    scale_color_brewer(palette = color_palette) +
    guides(color = "none")
  
    erg_alpha / erg_beta
}

muestra_promedios_ergodicos(posterior2, "Blues")
```

aqu칤, el 치rea sombreada representa los samplings del calentamiento ($n=667$). Despu칠s de ese periodo, e incluso un poco antes, se aprecia el comportamiento estacionario. Este comportamiento se esclarece con los promedios erg칩digos.

### Posterior de $\alpha$ y $\beta$

A continuaci칩n, visualizamos los muestras de las posteriores de $\alpha$ y $\beta$ con el modelo bayesiano.

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Visualizar las distribuciones posteriores de alpha y beta
mcmc_areas(fit, pars = c("alpha", "beta"), prob = 0.95) + 
  theme_minimal() +
  labs(
    title = expression(paste("Distribuciones posteriores de ", alpha, " y ", beta)),
    subtitle = "Con medianas e intervalos de credibilidad de 95%"
  ) +
  geom_vline(xintercept = 0, linetype = "dashed")
```

#### Intervalo de credibilidad

De la gr치fica anterior es f치cil ver que, $$E[\beta|x] \approx -0.99$$

El intervalo de credibilidad del $95\%$ de $\beta$ ser칤a de:

$$
p(1.98\leq\beta\leq-0.057|x) \approx 0.95
$$

#### Planteamiento de hip칩tesis

En particular, para la $\beta$ notamos que el intervalo de credibilidad del $95\%$ se encuentra del lado izquierdo del cero, lo que significa que $p(\beta<0|x) >0.95$. Si plantearamos una hip칩tesis sobre la $\beta$ dir칤amos que tenemos evidencia para afirmar que hay un efecto negativo entre los niveles de d칩sis y la probabilidad de que la rata desarrolle un tumor, de hecho, la probabilidad de que la pendiente $\beta$ sea negativa ser칤a $p(\beta <0 |x) \approx 0.98$.

En un planteamiento de hip칩tesis como el siguiente

$$
H_0: \beta < 0 \quad \text{vs} \quad H_a: \beta \geq 0
$$

la hip칩tesis $H_0$ tiene mayor plausibilidad.

# Ejercicio 2

Dado que el tama침o de las muestras en el problema anterior es muy peque침o, y en vista de la falta de informaci칩n inicial, las investigadoras se dieron a la tarea de buscar informaci칩n relevante en la literatura. Como producto de esta labor, encontraron datos de 10 estudios similares con ratas de la misma cepa. Desafortunadamente, todos estos datos correspond칤an a *controles*; es decir, ratas a las que no se les aplic칩 la droga. Los datos se presentan en la Tabla 2a. Aqu칤 $n_{0,i}$ y $y_{0,i}$ denotan, respectivamente, el n칰mero total de ratas y el n칰mero de ratas que presentaron un tumor en el i-칠simo estudio ($i=1,2,...,10$).

\begin{table}[h]
    \centering
    \begin{tabular}{||c |c |c||}
 \hline
        $Estudio \quad i$ & $n_{0,i}$ & $y_{0,i}$\\[0.5ex] 
 \hline\hline
        1 & 10 &1 \\
         \hline
         2&13 &2 \\
         \hline
          3& 48 &10 \\
         \hline
         4&19 & 5\\
         \hline
          5& 20 &0 \\
         \hline
         6& 18& 0\\
         \hline
          7& 25 & 2\\
         \hline
         8&49 &5 \\
         \hline
          9& 48 &9 \\
         \hline
         10& 19 &4 \\[1ex] 
 \hline        
    \end{tabular}
    \caption{Tabla 2a}
\end{table}

No satisfechas con estos datos, las investigadoras siguieron buscando trabajos recientes (no publicados). Finalmente encontraron dos reportes muy relevantes, de donde extrajeron los siguientes datos:

\begin{table}[h]
    \centering
    \begin{tabular}{||c |c |c||}
 \hline
        $x$ & $n_{x,11}$ & $y_{x,11}$\\[0.5ex] 
 \hline\hline
         0& 7 &3 \\
         \hline
         1& 16 &5 \\
         \hline
         2& 18 &2 \\[1ex] 
 \hline        
    \end{tabular}
    \caption{Tabla 2b}
\end{table}

\begin{table}[h]
    \centering
    \begin{tabular}{||c |c |c||}
 \hline
        $x$ & $n_{x,12}$ & $y_{x,12}$\\[0.5ex] 
 \hline\hline
         0& 5 &2 \\
         \hline
         1& 11 &1 \\
         \hline
         2& 9 &0 \\[1ex] 
 \hline        
    \end{tabular}
    \caption{Tabla 2c}
\end{table}

En vista de que para los datos de la Tabla 2a s칩lo se recab칩 informaci칩n de controles, el nivel de la dosis es $x=0$ en todos esos casos. Por lo tanto el modelo que propusieron para esos datos es 

$$Y_x\thicksim Bin(\pi_{0,1},n_{0,i}),\qquad i=1,2,...,10,$$

donde 

$$logit(\pi_{0,i})=\alpha_i, \qquad i=1,2,...,10.$$

Por otra parte, para los datos de las Tablas 2b y 2c (Estudios 11 y 12), las investigadoras supusieron un modelo de la misma forma que el del problema 1, es decir:

$$Y_x\thicksim Bin(\pi_{x,i},n_{x,i}) \qquad (x=0,1,2);\qquad i=11,12,$$

con 

$$logit(\pi_x)=\alpha_i +\beta_i x \qquad (x=0,1,2); \qquad i=11,12.$$

Para simplificar el an치lisis en esta etapa, las investigadoras decidieron considerar todos estos estudios suficientemenete similares como para suponer que los datos de las Tablas 1,2a,2b y 2c *provienen de un solo experimento*, de manera que $\alpha_1=\alpha_2=...=\alpha_{12}=\alpha$ y $\beta_{11}=\beta_{12}=\beta$.

Utilizando la misma distribuci칩n inicial que en el Ejercicio 1, se proporciona un resumen de la distribuci칩n final de $\beta$.

## Respuesta

Para abordar este problema, vamos a combinar los datos de todos los estudios (Tablas 1, 2a, 2b y 2c) en un solo modelo y realizar la inferencia bayesiana utilizando Stan. Mantendremos la misma distribuci칩n inicial no informativa para 
$\alpha$ y $\beta$, y modelaremos los datos de manera que 
$\alpha$ y $\beta$ sean comumes a todos los estudios.

### Definiendo nuevos modelos en `Stan`

Primero, definimos todos los datos del experimento tal como se presentan en las tablas.

```{r echo=FALSE, warning=FALSE, message=FALSE, error=FALSE, results=FALSE}
# Datos del experimento original (Tabla 1)
x_1 <- c(0, 1, 2)
n_x_1 <- c(14, 34, 34)
y_x_1 <- c(4, 4, 2)

# Datos de los estudios de control (Tabla 2a)
n_0 <- c(10, 13, 48, 19, 20, 18, 25, 49, 48, 19)
y_0 <- c(1, 2, 10, 5, 0, 0, 2, 5, 9, 4)

# Datos de los estudios 11 (Tabla 2b)
x_11 <- c(0, 1, 2)
n_x_11 <- c(7, 16, 18)
y_x_11 <- c(3, 5, 2)

# Datos de los estudios 12 (Tabla 2c)
x_12 <- c(0, 1, 2)
n_x_12 <- c(5, 11, 9)
y_x_12 <- c(2, 1, 0)
```

```{r}
model_string_2 <- "
data {
  int<lower=0> N1;      
  int<lower=0> n1[N1];  
  int<lower=0> y1[N1];  
  vector[N1] x1;        

  int<lower=0> N0;      
  int<lower=0> n0[N0];  
  int<lower=0> y0[N0];  

  int<lower=0> N11;     
  int<lower=0> n11[N11];
  int<lower=0> y11[N11];
  vector[N11] x11;      

  int<lower=0> N12;      
  int<lower=0> n12[N12]; 
  int<lower=0> y12[N12]; 
  vector[N12] x12;       
}

parameters {
  real alpha;
  real beta; 
}

model {
  alpha ~ normal(0, 31.62278);
  beta ~ normal(0, 31.62278);

  for (i in 1:N1) {
    y1[i] ~ binomial_logit(n1[i], alpha + beta * x1[i]);
  }

  for (i in 1:N0) {
    y0[i] ~ binomial_logit(n0[i], alpha);
  }

  for (i in 1:N11) {
    y11[i] ~ binomial_logit(n11[i], alpha + beta * x11[i]);
  }

  for (i in 1:N12) {
    y12[i] ~ binomial_logit(n12[i], alpha + beta * x12[i]);
  }
}
"
```

Aqu칤, al igual que en el modelo anterior, definimos las distribuciones a priori de los par치metros a estimar: $\alpha \sim N(0, 31.62278)$ y $\beta \sim N(0, 31.62278)$, donde $\sigma=\sqrt{\sigma^2}= \sqrt{1000}=31.62278$ ya que `Stan` recibe desviaci칩n est치ndar como par치metro y no la varianza. Adem치s, definimos 4 verosimilitudes distintas para:

* Datos originales: `y1[i] ~ binomial_logit(n1[i], alpha + beta * x1[i]);`
* Estudios de controles: `y0[i] ~ binomial_logit(n0[i], alpha);`
* Estudio 11: `y11[i] ~ binomial_logit(n11[i], alpha + beta * x11[i]);`
* Estuio 12: `y12[i] ~ binomial_logit(n12[i], alpha + beta * x12[i]);`

Estos son usados en el modelo para estimar las distribuciones de $\alpha$ y $\beta$. 

### Ajustando el modelo con los datos

```{r echo=FALSE, warning=FALSE, message=FALSE, error=FALSE, results=FALSE}
# Preparar los datos para Stan
data_combinada <- list(
  N1 = length(x_1), n1 = n_x_1, y1 = y_x_1, x1 = x_1,
  N0 = length(n_0), n0 = n_0, y0 = y_0,
  N11 = length(x_11), n11 = n_x_11, y11 = y_x_11, x11 = x_11,
  N12 = length(x_12), n12 = n_x_12, y12 = y_x_12, x12 = x_12
)

# Compilar el modelo
modelo_combinado <- stan_model(model_code = model_string_2)

# Ajustar el modelo a los datos
fit_combinado <- sampling(
  object = modelo_combinado, 
  data = data_combinada, 
  iter = 5000,
  warmup = 2000,
  chains = 4,
  thin = 3,
  seed = 123
)
```

```{r echo=FALSE}
# Resumen de los resultados
print(fit_combinado, pars = c("alpha", "beta"))
```

### Diagn칩stico del modelo

```{r echo=FALSE}
# Extraer las muestras de la distribuci칩n posterior
posterior_samples_combinado <- extract(fit_combinado)
posterior_samples_combinado_2 <- extract(fit_combinado, inc_warmup = TRUE, permuted = FALSE)

# Cambiando el color para diferenciar del modelo anterior
color_scheme_set("purple")

# Aqu칤 va un bplot!!! 游뗵
# Usando `posterior_samples_combinado$beta`

mcmc_trace(
  posterior_samples_combinado_2, 
  pars = c("alpha", "beta"),
  n_warmup = 667, 
  facet_args = list(nrow = 2, labeller = label_parsed)
) + theme_minimal() + facet_text(size = 12)

muestra_promedios_ergodicos(posterior_samples_combinado_2, color_palette = "Purples")
```

### Posterior de $\alpha$ y $\beta$

A continuaci칩n, visualizamos los muestras de las posteriores de $\alpha$ y $\beta$ con el modelo bayesiano incluyendo los 12 estudios adicionales. Se aprecia que $\alpha$ se diferencia de $\beta$ volvi칠ndose m치s negativo que en el resultado de `Stan` anterior, siendo aqu칤 $E[\alpha|x]\approx-1.635$

```{r echo=FALSE, warning=FALSE, message=FALSE}
mcmc_areas(fit_combinado, pars = c("alpha", "beta"), prob = 0.95) + 
  theme_minimal() +
  labs(
    title = expression(paste("Distribuciones posteriores de ", alpha, " y ", beta, " para el modelo combinado")),
    subtitle = "Con medianas e intervalos de credibilidad de 95%"
  ) +
  geom_vline(xintercept = 0, linetype = "dashed")

# beta_samples <- posterior_samples_combinado$beta
# sum(beta_samples < 0) / length(beta_samples)
```

#### Intervalo de credibilidad

De la gr치fica anterior es f치cil calcular el intervalo de credibilidad o high density interval (HDI por sus siglas en ingl칠s).

$$
P[-0.859 \leq\beta\leq0.0226] \approx 0.95
$$

#### Planteamiento de hip칩tesis

Podemos plantear una hip칩tesis sobre la probabilidad de $\beta$ como lo hicimos en la pregunta anterior. Si las investigadoras se plantearan si existe una relaci칩n negativa entre el nivel de dosis y la probabilidad de presentar el tumor para una rata, tendr칤an que calcular:

$$
H_0: \beta < 0 \quad \text{vs} \quad H_a: \beta \geq 0
$$

desde el enfoque bayesiano, esto equivaldr칤a a calcular la plausibilidad de que la $\beta$ sea negativa.

Con este modelo propuesto, observamos que: $p(\beta<0) \approx 0.9665$

\clearpage

# Ejercicio 3: Modelo Jer치rquico

Poco tiempo despu칠s, una de las investigadoras tuvo la oportunidad de asistir a un curso de An치lisis Bayesiano de Modelos Jer치rquicos y convenci칩 al resto del equipo de que 칠sa es la manera m치s apropiada de analizar los datos con los que contaban. Espec칤ficamente, dado que todos los estudios eran similares, consideraron que pod칤an utilizar los 12 estudios que encontraron en la literatura para complementar la informaci칩n de su experimento original (ver Tabla 1).

Las investigadoras supusieron entonces que los par치metros ${\alpha_1,\alpha_2,...,\alpha_{12}}$ eran intercambiables, con distribuci칩n com칰n $N(\alpha^*,\sigma^2_\alpha)$, y tambi칠n que los par치metros 
$\beta,\beta_{11},\beta_{12}$ eran intercambiables con distribuci칩n com칰n $N(\beta^*,\sigma^2_\beta)$. Finalmente, tanto para $\alpha^*$ como para $\beta^*$ supusieron una distribuci칩n $N(0,100)$, mientras que para $\tau_\alpha=1/\sigma^2_\alpha$ y $\tau_\beta=1/\sigma^2_\beta$ consideraron una distribuci칩n $Gamma(0.01,0.01)$.

Se propone un resumen de la distribuci칩n final de $\beta$ (la correspondiente al Ejercicio 1) bajo estas condiciones.

\clearpage

## Respuesta

### Definiendo el modelo en `Stan`

```{r}
model_string_3 <- "
data {
  int<lower=0> N1; 
  int<lower=0> n1[N1];  
  int<lower=0> y1[N1];  
  vector[N1] x1;        

  int<lower=0> N0;      
  int<lower=0> n0[N0];  
  int<lower=0> y0[N0];  

  int<lower=0> N11;     
  int<lower=0> n11[N11];
  int<lower=0> y11[N11];
  vector[N11] x11;      

  int<lower=0> N12;     
  int<lower=0> n12[N12];
  int<lower=0> y12[N12];
  vector[N12] x12;      
}

parameters {
  real alpha_estrella;        
  real<lower=0> tau_alpha;
  vector[12] alpha;  

  real beta_estrella;         
  real<lower=0> tau_beta; 
  real beta;              
  real beta_11;           
  real beta_12;           
}

transformed parameters {
  real sigma_alpha = 1 / sqrt(tau_alpha); 
  real sigma_beta = 1 / sqrt(tau_beta);
}

model {
  alpha_estrella ~ normal(0, 10);
  beta_estrella ~ normal(0, 10);
  tau_alpha ~ gamma(0.01, 0.01);
  tau_beta ~ gamma(0.01, 0.01);

  alpha ~ normal(alpha_estrella, sigma_alpha);
  beta ~ normal(beta_estrella, sigma_beta);
  beta_11 ~ normal(beta_estrella, sigma_beta);
  beta_12 ~ normal(beta_estrella, sigma_beta);

  for (i in 1:N1) {
    y1[i] ~ binomial_logit(n1[i], alpha[1] + beta * x1[i]);
  }

  for (i in 1:N0) {
    y0[i] ~ binomial_logit(n0[i], alpha[i+1]);
  }

  for (i in 1:N11) {
    y11[i] ~ binomial_logit(n11[i], alpha[11] + beta_11 * x11[i]);
  }

  for (i in 1:N12) {
    y12[i] ~ binomial_logit(n12[i], alpha[12] + beta_12 * x12[i]);
  }
}
"
```

```{r echo=FALSE}
# Datos del experimento original (Tabla 1)
x_1 <- c(0, 1, 2)
n_x_1 <- c(14, 34, 34)
y_x_1 <- c(4, 4, 2)

# Datos de los estudios de control (Tabla 2a)
n_0 <- c(10, 13, 48, 19, 20, 18, 25, 49, 48, 19)
y_0 <- c(1, 2, 10, 5, 0, 0, 2, 5, 9, 4)

# Datos de los estudios 11 (Tabla 2b)
x_11 <- c(0, 1, 2)
n_x_11 <- c(7, 16, 18)
y_x_11 <- c(3, 5, 2)

# Datos de los estudios 12 (Tabla 2c)
x_12 <- c(0, 1, 2)
n_x_12 <- c(5, 11, 9)
y_x_12 <- c(2, 1, 0)

modelo_jerarquico <- stan_model(model_code = model_string_3)
```

```{r}
data_jerarquico <- list(
  # Estudios original
  N1 = length(x_1), n1 = n_x_1, y1 = y_x_1, x1 = x_1,
  
  # Estudios de ceros
  N0 = length(n_0), n0 = n_0, y0 = y_0,
  
  # Estudios 11
  N11 = length(x_11), n11 = n_x_11, y11 = y_x_11, x11 = x_11,
  
  # Estudio 12
  N12 = length(x_12), n12 = n_x_12, y12 = y_x_12, x12 = x_12
)


fit_jerarquico <- sampling(
  object = modelo_jerarquico,
  data = data_jerarquico,
  iter = 5000,
  warmup = 2000,
  chains = 4,
  thin = 3,
  seed = 123
)
```

```{r}
color_scheme_set("green")

posterior_jerarquico <- extract(fit_jerarquico)
posterior_jerarquico_2 <- extract(fit_jerarquico, inc_warmup = TRUE, permuted = FALSE)

# Aqu칤 va un bplot!!! 游뗵
# posterior_jerarquico$beta

mcmc_trace(
  posterior_jerarquico_2, 
  pars = c("beta", "beta_11", "beta_12"),
  n_warmup = 667, 
  facet_args = list(nrow = 2, labeller = label_parsed)
) + theme_minimal() + facet_text(size = 12)

mcmc_areas(
  fit_jerarquico, pars = c("beta", "beta_11", "beta_12"), prob = 0.95
) + geom_vline(xintercept = 0, linetype = "dashed") + theme_minimal()
```

# Ejercicio 4: Modelos



## Comparaci칩n de modelos

## Discusi칩n de resultados

\clearpage
# Comentarios finales
\clearpage
# Referencias

\begin{itemize}

    \item Mart칤n de Civetta MT y  Civetta JD.(2011). Carcinog칠nesis. Sal칰d P칰blica Mex;53:405-414.

\end{itemize}
