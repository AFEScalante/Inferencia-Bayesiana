---
header-includes:
- \usepackage[american,spanish,mexico]{babel}
- \usepackage{adjustbox,mathtools,amsmath,caption,geometry,xfrac,placeins,subfig}
- \usepackage{listings}
- \providecommand{\P}{\mathbb{P}}
- \providecommand{\N}{\mathbb{N}}
- \providecommand{\E}{\mathbb{E}}

output:
  pdf_document:
    #pandoc_args: --listings
keep_tex: yes
includes:
      in_header: preamble.tex
fontsize: 11pt
urlcolor: blue
geometry: left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm
---

\lstset{
breaklines=true, basicstyle=\ttfamily
}
\graphicspath{{/Users/angelescalante/Desktop/Inferencia-Bayesiana/proyecto-final}}
\newgeometry{left=1cm,right=2.5cm,top=2.5cm,bottom=2.5cm}
\begin{titlepage} 
	\raggedleft 
	 \raisebox{120ex}{\makebox[2.4cm][l]{\includegraphics[width=3cm]{unam}}}
	 \raisebox{1ex}{\adjustbox{left=-2.571cm}{|}{\makebox[2.5cm][l]{\includegraphics[width=2.5cm]{iimas}}}}
	\rule{1pt}{\textheight}
	\hspace{0.05\textwidth}
	\parbox[b]{0.75\textwidth}{ 
		{\huge\text{Universidad Nacional Autónoma de México}}\\[5\baselineskip]
		{\Huge\bfseries Proyecto Final \\[1.5\baselineskip]}\\[1\baselineskip] 
		{\LARGE\bfseries Inferencia Bayesiana \\[2.25\baselineskip]}\\[1\baselineskip]
		{\LARGE\textsc{ Ángel Fernando Escalante López \\ [0.5\baselineskip] Shadanna Ortega Hernández}}
		
		\vspace{0.30\textheight}
		{\Large\textsc{Dr. Eduardo Gutiérrez Peña}}\\
		\\
		{\large{\noindent Instituto de Investigaciones en Matemáticas Aplicadas y en Sistemas}}\\[\baselineskip]}
\end{titlepage}

\newgeometry{left=3cm,right=3cm,top=2.5cm,bottom=2.5cm}

\tableofcontents
\clearpage

```{r setup, include=FALSE, echo=FALSE, warning=FALSE}
library(tidyverse)
library(ggtext)
library(kableExtra)
library(jtools)
library(effects)
library(MASS)
library(vcdExtra)
library(patchwork)
library(rstan)
library(bayesplot)
library(RColorBrewer)
```

```{r echo=FALSE}
### Funciones auxiliares ---
grafica_ajuste_curva <- function(posterior_samples, alpha_var, beta_var) {
  alpha_samples <- posterior_samples[[alpha_var]]
  beta_samples <- posterior_samples[[beta_var]]
  
  alpha_mean <- mean(alpha_samples)
  beta_mean <- mean(beta_samples)
  
  q1_alpha <- quantile(alpha_samples, 0.025) |> as.numeric()
  q1_beta <- quantile(beta_samples, 0.025) |> as.numeric()
  
  q2_alpha <- quantile(alpha_samples, 0.975) |> as.numeric()
  q2_beta <- quantile(beta_samples, 0.975) |> as.numeric()
  
  x_seq <- seq(0, 2, length.out = 100)
  
  anti_logit <- function(x) {
    1 / (1 + exp(-x))
  }
  
  curvas_tbl <- tibble(
    x = x_seq,
    q1_curva = anti_logit(q1_alpha + q1_beta * x),
    q2_curva = anti_logit(q2_alpha + q2_beta * x),
    est_curva = anti_logit(alpha_mean + beta_mean * x)
  )

  ggplot(curvas_tbl, aes(x = x, y = est_curva)) + 
    geom_line() +
    geom_line(aes(x = x, y = q1_curva), color = "red", linetype = "dashed") +
    geom_line(aes(x = x, y = q2_curva), color = "red", linetype = "dashed") +
    ylim(c(0, 1)) +
    theme_minimal() +
    labs(x = "Nivel de dósis (contínua)", 
         y = expression(pi[x]),
         title = "**Curva de ajuste del modelo**",
         subtitle = "Intervalo de credibilidad del 95%"
    ) + theme(plot.title = element_markdown())
}

```


# Introducción

En la actualidad, una de las principales causas de muerte es por la enfermedad conocida como cáncer. El cáncer comienza en una célula normal que cambia a una célula neoplásica\footnote{Célula con una multiplicación o crecimiento anormal en un tejido del organismo.} a través de varias mutaciones en varios genes a lo largo de mucho tiempo, podrían ser años, de estar expuesto a un agente carcinogenético \footnote{Agente capaz de causar cáncer.}. No obstante, las mutaciones inducidas por los carcinógenos no son la única vía que afecta a la célula, sino que a lo largo de cada división celular se producen errores espontáneos en cada duplicación y los mismos se van acumulando constituyendo un factor intrínseco de riesgo (Martín de Civetta y Civetta, 2011). Por lo cual, es de suma importancia estudiar la cura para esta enfermedad.

En este contexto, el presente trabajo analizará desde una perspectiva bayesiana de un experimento de un tipo de tumor en un grupo de ratas, dadas diferentes dosis de una droga. En otras palabras, estudiar la tasa a la que el riesgo de tumor crece o decrece como función de la dosis.

Para ello, se examinarán tres perspectivas de acuerdo al tipo de información inicial, después se hará la una comparación entre modelos y por último unos comentarios finales.

# Ejercicio 1:

Con el propósito de estudiar la relación entre la dosis y la respuesta, se tienen los datos del experimento en el cuadro 1, donde x representa el nivel de la dosis, mientras que $n_x$ y $y_x$ denotan respectivamente, el número de ratas tratadas y el número de ratas que presentan tumor en cada nivel $(x=0,1,2)$.

\begin{table}[h]
    \centering
    \begin{tabular}{||c |c |c||}
 \hline
        $x$ & $n_x$ & $y_x$\\[0.5ex] 
 \hline\hline
         0& 14 &4 \\
         \hline
         1& 34 &4 \\
         \hline
         2& 34 &2 \\[1ex] 
 \hline        
    \end{tabular}
    \caption{Datos}
\end{table}


Sea $\pi_x$ la probabilidad de que una rata en el grupo $x$ desarrolle un tumor. Entonces, se considera el modelo 
$$Y_x\thicksim Bin(\pi_x,n_x)\qquad (x=0,1,2).$$

Dado que las investigadoras están interesadas en la forma como varía $\pi_x$ en función de la dosis $x$, propusieron el modelo

$$logit(\pi_x)=\alpha+\beta x \qquad (x=0,1,2).$$

El parámetro de interés para las investigadoras es la pendiente $\beta$, pero no cuentan con información inicial sobre su valor.

Entonces, se realizará un resumen de la distribución final de $\beta$ suponiendo una distribución inicial no informativa en la que $\alpha$ y $\beta$ se asumen independientes, con $\alpha \thicksim N(0,1000)$ y $\beta \thicksim N(0,1000)$; esto es, con media 0 y varianza 1000.

\clearpage

## Respuesta

De forma analítica el modelado de la relación dosis-respuesta sería mediante un modelo lineal generalizado, en específico, un modelo de regresión logística. Sin embargo, en este trabajo se utilizarán métodos de simulación\footnote{Los métodos de simulación se refieren a la obtención de pseudo-muestras que se originan de una distribución de probabilidad en una computadora, también conocidos como Métodos de Monte Carlo, pues e introduce un nivel de aleatoredad en el análisis (Bravo *et. al.*, 2008).}, en particular, Métodos Monte Carlo de Cadenas de Markov (MCMC)\footnote{ Los Métodos Monte Carlo de Cadenas de Markov tienen como objetivo encontrar una cadena de Markov en el espacio de parámetros, de manera tal que la distribución de equilibrio o estacionaria e la cadena coincida con la distribución posterior (Bravo *et. al.*, 2008).}. Por lo cual, se realizan un número considerable de simulaciones, así como su diagnóstico de la convergencia de los valores obtenidos. Lo anterior, para asegurar que la inferencia se realice sobre simulaciones que son representativas de la distribución de interés. Por último, el modelado se realizará con *Stan*.

### Definiendo modelo con `Stan`

Considerando el contexto del problema, se selecciona un modelo binomial. Entonces, la declaración del modelo binomial se hace a través de la función `binomial_logit()` de `Stan`, que recibe como segundo parámetro la inversa de la función logit\footnote{Stan User Guide}, además se usa $\sigma=\sqrt{\sigma^2}= \sqrt{1000}=31.62278$ ya que `Stan` recibe desviación estándar como parámetro y no la varianza.


```{r message=FALSE, warning=FALSE, error=FALSE}
model_string <- 
"
data {
  int<lower=0> N;
  int<lower=0> n[N];
  int<lower=0> y[N];
  vector[N] x;
}

parameters {
  real alpha;
  real beta;
}

model {
  alpha ~ normal(0, 31.62278);
  beta ~ normal(0, 31.62278);
  
  for (i in 1:N) {
    y[i] ~ binomial_logit(n[i], alpha + beta * x[i]);
  }
}
"
```

### Muestreando el modelo con datos del estudio

Para este modelo, se utilizaron los siguientes parámetros en `Stan`:

- Número de iteraciones = 5000
- Warmup (calentamiento) = 2000
- Thin = 3
- Número de cadenas = 4

```{r echo=FALSE, warning=FALSE, message=FALSE, error=FALSE, results=FALSE}
# Datos del experimento
x <- c(0, 1, 2)
n_x <- c(14, 34, 34)
y_x <- c(4, 4, 2)

# Preparar los datos para Stan
data <- list(N = length(x), n = n_x, y = y_x, x = x)

# Compilar el modelo
modelo_1 <- stan_model(model_code = model_string, verbose = FALSE)

# Ajustar el modelo a los datos
fit <- sampling(
  modelo_1,
  data = data,
  iter = 5000,
  warmup = 2000,
  thin = 3,
  chains = 4,
  seed = 123,
  verbose = FALSE,
  open_progress = FALSE
)
```

```{r echo=FALSE, results=FALSE}
# Imprimiendo resultados del modelo
print(fit, pars = c("alpha", "beta"))
```

\begin{table}[h]
\begin{tabular}{lcccccccccc}
\cline{2-11}
\multicolumn{1}{l|}{}                & \multicolumn{1}{c|}{\textit{mean}} & \multicolumn{1}{c|}{\textit{se\_mean}} & \multicolumn{1}{c|}{\textit{sd}} & \multicolumn{1}{c|}{\textit{2.5\%}} & \multicolumn{1}{c|}{\textit{25\%}} & \multicolumn{1}{c|}{\textit{50\%}} & \multicolumn{1}{c|}{\textit{75\%}} & \multicolumn{1}{c|}{\textit{97.5\%}} & \multicolumn{1}{c|}{\textit{n\_eff}} & \multicolumn{1}{c|}{\textit{Rhat}} \\ \hline
\multicolumn{1}{|c|}{\textbf{alpha}} & \multicolumn{1}{c|}{-1.01}         & \multicolumn{1}{c|}{0.01}              & \multicolumn{1}{c|}{0.56}        & \multicolumn{1}{c|}{-2.16}          & \multicolumn{1}{c|}{-1.37}         & \multicolumn{1}{c|}{-1}            & \multicolumn{1}{c|}{-0.63}         & \multicolumn{1}{c|}{0.03}            & \multicolumn{1}{c|}{2604}            & \multicolumn{1}{c|}{1}             \\ \hline
\multicolumn{1}{|c|}{\textbf{beta}}  & \multicolumn{1}{c|}{-0.99}         & \multicolumn{1}{c|}{0.01}              & \multicolumn{1}{c|}{0.5}         & \multicolumn{1}{c|}{-1.98}          & \multicolumn{1}{c|}{-1.31}         & \multicolumn{1}{c|}{-0.98}         & \multicolumn{1}{c|}{-0.64}         & \multicolumn{1}{c|}{-0.06}           & \multicolumn{1}{c|}{2582}            & \multicolumn{1}{c|}{1}             \\ \hline
                                     & \multicolumn{1}{l}{}               & \multicolumn{1}{l}{}                   & \multicolumn{1}{l}{}             & \multicolumn{1}{l}{}                & \multicolumn{1}{l}{}               & \multicolumn{1}{l}{}               & \multicolumn{1}{l}{}               & \multicolumn{1}{l}{}                 & \multicolumn{1}{l}{}                 & \multicolumn{1}{l}{}              
\end{tabular}
\caption{Ajuste del estudio 1}
\end{table}



### Diagnóstico del modelo    

Con base en la tabla anterior, se puede ver que el **Rhat**\footnote{$\hat{R}$ estima la reducción de la escala potencial. Es decir, para monitorear la convergencia en los algoritmos de simulación MCMC se realiza mediante la estimación de un factor por el cual la escala de la distribución actual del parámetro $\psi$ puede ser reducida suponiendo que se continuan las simulaciones en el límite $n \to \infty$, lo cual va a 1 si $n \to \infty$ (Bravo *et. al.*, 2008).} es exactamente 1 para las cadenas de $\alpha$ y $\beta$, lo cuál representaría convergencia para ambos parámetros. De igual manera, esto se aprecia a través de los gráficos de las trazas:

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Extraer las muestras de la distribución posterior
posterior_samples <- extract(fit)
posterior2 <- extract(fit, inc_warmup = TRUE, permuted = FALSE)

color_scheme_set("blue")

mcmc_trace(
  posterior2, 
  pars = c("alpha", "beta"),
  n_warmup = 667, 
  facet_args = list(nrow = 2, labeller = label_parsed)
) + theme_minimal() + facet_text(size = 12) + labs(caption=c("Figura 1"))

# Calcular los promedios ergódicos de las muestras
compute_ergodic_means <- function(samples) {
  cumsum(samples) / seq_along(samples)
}

muestra_promedios_ergodicos <- function(posterior, color_palette = "Blues") {
  alpha_samples <- as.matrix(posterior[, , "alpha"])
  beta_samples <- as.matrix(posterior[, , "beta"])
  
  alpha_ergodic_means <- apply(alpha_samples, 2, compute_ergodic_means)
  
  # Crear un data frame para ggplot2
  iteration <- seq_len(nrow(alpha_ergodic_means))
  df_alpha <- data.frame(iteration, alpha_ergodic_means)
  
  # Graficar los promedios ergódicos para alpha
  erg_alpha <- ggplot(df_alpha, aes(x = iteration)) +
    geom_line(aes(y = chain.1, color = "Cadena 1")) +
    geom_line(aes(y = chain.2, color = "Cadena 2")) +
    geom_line(aes(y = chain.3, color = "Cadena 3")) +
    geom_line(aes(y = chain.4, color = "Cadena 4")) +
    labs(title = expression(alpha),
         caption ="Figura 2",
         x = "Iteración",
         color = "Cadena",
         y = "") +
    theme_minimal() +
    scale_color_brewer(palette = color_palette) +
    guides(color = "none")
  
  beta_ergodic_means <- apply(beta_samples, 2, compute_ergodic_means)
  df_beta <- data.frame(iteration, beta_ergodic_means)
  
  # Graficar los promedios ergódicos para beta
  erg_beta <- ggplot(df_beta, aes(x = iteration)) +
    geom_line(aes(y = chain.1, color = "Cadena 1")) +
    geom_line(aes(y = chain.2, color = "Cadena 2")) +
    geom_line(aes(y = chain.3, color = "Cadena 3")) +
    geom_line(aes(y = chain.4, color = "Cadena 4")) +
    labs(title = expression(beta),
         caption ="Figura 3",
          x = "Iteración",
         y = "",
         color = "Cadena") +
    theme_minimal() +
    scale_color_brewer(palette = color_palette) +
    guides(color = "none")
  
    erg_alpha / erg_beta
}

muestra_promedios_ergodicos(posterior2, "Blues")
```

En la figura 1, el área sombreada representa las muestras del calentamiento ($n=667$), pues de esta manera se pueden omitir los primeros valores de las cadenas para que salgan de una primera fase de inestabilidad. Después de ese periodo, e incluso un poco antes, se puede ver el comportamiento estacionario. Este comportamiento se esclarece con los promedios ergódigos (veáse figuras 2 y 3).

\clearpage
### Posterior de $\alpha$ y $\beta$

En este contexto, en la figura 4, visualizamos las muestras de las posteriores de $\alpha$ y $\beta$ del modelo.

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Visualizar las distribuciones posteriores de alpha y beta
mcmc_areas(fit, pars = c("alpha", "beta"), prob = 0.95) + 
  theme_minimal() +
  labs(
    title = expression(paste("Distribuciones posteriores de ", alpha, " y ", beta)),
    subtitle = "Con medianas e intervalos de credibilidad de 95%",
    caption ="Figura 4",
  ) +
  geom_vline(xintercept = 0, linetype = "dashed")
```

#### Intervalo de credibilidad

De la gráfica anterior, es fácil ver que la media de la distribución final de $\beta$ es muy cercana a -1. En específico, la estimación puntual de la esperanza es: $$E[\beta|y] \approx -0.99$$

El intervalo de credibilidad del $95\%$ de $\beta$ sería de:

$$
p(1.98\leq\beta\leq-0.057|y) \approx 0.95
$$

#### Planteamiento de hipótesis

En particular, para la $\beta$ notamos que el intervalo de credibilidad del $95\%$ se encuentra del lado izquierdo del cero, lo que significa que $p(\beta<0|y) >0.95$. Si plantearamos una hipótesis sobre la $\beta$ diríamos que tenemos evidencia para afirmar que hay un efecto negativo entre los niveles de dósis y la probabilidad de que la rata desarrolle un tumor, de hecho, la probabilidad de que la pendiente $\beta$ sea negativa sería $p(\beta <0 |y) \approx 0.98$.

En un planteamiento de hipótesis como el siguiente

$$
H_0: \beta < 0 \quad \text{vs} \quad H_a: \beta \geq 0
$$

la hipótesis $H_0$ tiene mayor plausibilidad.

### Curva de ajuste

```{r echo=FALSE}
grafica_ajuste_curva(posterior_samples, "alpha", "beta")+labs(
       caption = "Figura 5")
```

# Ejercicio 2

Dado que el tamaño de las muestras en el problema anterior es muy pequeño, y en vista de la falta de información inicial, las investigadoras se dieron a la tarea de buscar información relevante en la literatura. Como producto de esta labor, encontraron datos de 10 estudios similares con ratas de la misma cepa. Desafortunadamente, todos estos datos correspondían a *controles*; es decir, ratas a las que no se les aplicó la droga. Los datos se presentan en la Tabla 2a. Aquí $n_{0,i}$ y $y_{0,i}$ denotan, respectivamente, el número total de ratas y el número de ratas que presentaron un tumor en el i-ésimo estudio ($i=1,2,...,10$).

\begin{table}[h]
    \centering
    \begin{tabular}{||c |c |c||}
 \hline
        $Estudio \quad i$ & $n_{0,i}$ & $y_{0,i}$\\[0.5ex] 
 \hline\hline
        1 & 10 &1 \\
         \hline
         2&13 &2 \\
         \hline
          3& 48 &10 \\
         \hline
         4&19 & 5\\
         \hline
          5& 20 &0 \\
         \hline
         6& 18& 0\\
         \hline
          7& 25 & 2\\
         \hline
         8&49 &5 \\
         \hline
          9& 48 &9 \\
         \hline
         10& 19 &4 \\[1ex] 
 \hline        
    \end{tabular}
    \caption{Tabla 2a}
\end{table}

No satisfechas con estos datos, las investigadoras siguieron buscando trabajos recientes (no publicados). Finalmente encontraron dos reportes muy relevantes, de donde extrajeron los siguientes datos:

\begin{table}[h]
    \centering
    \begin{tabular}{||c |c |c||}
 \hline
        $x$ & $n_{x,11}$ & $y_{x,11}$\\[0.5ex] 
 \hline\hline
         0& 7 &3 \\
         \hline
         1& 16 &5 \\
         \hline
         2& 18 &2 \\[1ex] 
 \hline        
    \end{tabular}
    \caption{Tabla 2b}
\end{table}

\begin{table}[h]
    \centering
    \begin{tabular}{||c |c |c||}
 \hline
        $x$ & $n_{x,12}$ & $y_{x,12}$\\[0.5ex] 
 \hline\hline
         0& 5 &2 \\
         \hline
         1& 11 &1 \\
         \hline
         2& 9 &0 \\[1ex] 
 \hline        
    \end{tabular}
    \caption{Tabla 2c}
\end{table}

En vista de que para los datos de la Tabla 2a sólo se recabó información de controles, el nivel de la dosis es $x=0$ en todos esos casos. Por lo tanto el modelo que propusieron para esos datos es 

$$Y_x\thicksim Bin(\pi_{0,1},n_{0,i}),\qquad i=1,2,...,10,$$

donde 

$$logit(\pi_{0,i})=\alpha_i, \qquad i=1,2,...,10.$$

Por otra parte, para los datos de las Tablas 2b y 2c (Estudios 11 y 12), las investigadoras supusieron un modelo de la misma forma que el del problema 1, es decir:

$$Y_x\thicksim Bin(\pi_{x,i},n_{x,i}) \qquad (x=0,1,2);\qquad i=11,12,$$

con 

$$logit(\pi_x)=\alpha_i +\beta_i x \qquad (x=0,1,2); \qquad i=11,12.$$

Para simplificar el análisis en esta etapa, las investigadoras decidieron considerar todos estos estudios suficientemenete similares como para suponer que los datos de las Tablas 1,2a,2b y 2c *provienen de un solo experimento*, de manera que $\alpha_1=\alpha_2=...=\alpha_{12}=\alpha$ y $\beta_{11}=\beta_{12}=\beta$.

Utilizando la misma distribución inicial que en el Ejercicio 1, se proporciona un resumen de la distribución final de $\beta$.

## Respuesta

Para abordar este problema, vamos a combinar los datos de todos los estudios (Tablas 1, 2a, 2b y 2c) en un solo modelo y realizar la inferencia bayesiana utilizando Stan. Mantendremos la misma distribución inicial no informativa para 
$\alpha$ y $\beta$, y modelaremos los datos de manera que 
$\alpha$ y $\beta$ sean comumes a todos los estudios.

### Definiendo nuevos modelos en `Stan`

Primero, definimos todos los datos del experimento tal como se presentan en las tablas.

```{r echo=FALSE, warning=FALSE, message=FALSE, error=FALSE, results=FALSE}
# Datos del experimento original (Tabla 1)
x_1 <- c(0, 1, 2)
n_x_1 <- c(14, 34, 34)
y_x_1 <- c(4, 4, 2)

# Datos de los estudios de control (Tabla 2a)
n_0 <- c(10, 13, 48, 19, 20, 18, 25, 49, 48, 19)
y_0 <- c(1, 2, 10, 5, 0, 0, 2, 5, 9, 4)

# Datos de los estudios 11 (Tabla 2b)
x_11 <- c(0, 1, 2)
n_x_11 <- c(7, 16, 18)
y_x_11 <- c(3, 5, 2)

# Datos de los estudios 12 (Tabla 2c)
x_12 <- c(0, 1, 2)
n_x_12 <- c(5, 11, 9)
y_x_12 <- c(2, 1, 0)
```

```{r}
model_string_2 <- "
data {
  int<lower=0> N1;      
  int<lower=0> n1[N1];  
  int<lower=0> y1[N1];  
  vector[N1] x1;        

  int<lower=0> N0;      
  int<lower=0> n0[N0];  
  int<lower=0> y0[N0];  

  int<lower=0> N11;     
  int<lower=0> n11[N11];
  int<lower=0> y11[N11];
  vector[N11] x11;      

  int<lower=0> N12;      
  int<lower=0> n12[N12]; 
  int<lower=0> y12[N12]; 
  vector[N12] x12;       
}

parameters {
  real alpha;
  real beta; 
}

model {
  alpha ~ normal(0, 31.62278);
  beta ~ normal(0, 31.62278);

  for (i in 1:N1) {
    y1[i] ~ binomial_logit(n1[i], alpha + beta * x1[i]);
  }

  for (i in 1:N0) {
    y0[i] ~ binomial_logit(n0[i], alpha);
  }

  for (i in 1:N11) {
    y11[i] ~ binomial_logit(n11[i], alpha + beta * x11[i]);
  }

  for (i in 1:N12) {
    y12[i] ~ binomial_logit(n12[i], alpha + beta * x12[i]);
  }
}
"
```

Aquí, al igual que en el modelo anterior, definimos las distribuciones a priori de los parámetros a estimar: $\alpha \sim N(0, 31.62278)$ y $\beta \sim N(0, 31.62278)$, donde $\sigma=\sqrt{\sigma^2}= \sqrt{1000}=31.62278$ ya que `Stan` recibe desviación estándar como parámetro y no la varianza. Además, definimos 4 verosimilitudes distintas para:

* Datos originales: `y1[i] ~ binomial_logit(n1[i], alpha + beta * x1[i]);`
* Estudios de controles: `y0[i] ~ binomial_logit(n0[i], alpha);`
* Estudio 11: `y11[i] ~ binomial_logit(n11[i], alpha + beta * x11[i]);`
* Estuio 12: `y12[i] ~ binomial_logit(n12[i], alpha + beta * x12[i]);`

Estos son usados en el modelo para estimar las distribuciones de $\alpha$ y $\beta$. 

### Ajustando el modelo con los datos

```{r echo=FALSE, warning=FALSE, message=FALSE, error=FALSE, results=FALSE}
# Preparar los datos para Stan
data_combinada <- list(
  N1 = length(x_1), n1 = n_x_1, y1 = y_x_1, x1 = x_1,
  N0 = length(n_0), n0 = n_0, y0 = y_0,
  N11 = length(x_11), n11 = n_x_11, y11 = y_x_11, x11 = x_11,
  N12 = length(x_12), n12 = n_x_12, y12 = y_x_12, x12 = x_12
)

# Compilar el modelo
modelo_combinado <- stan_model(model_code = model_string_2)

# Ajustar el modelo a los datos
fit_combinado <- sampling(
  object = modelo_combinado, 
  data = data_combinada, 
  iter = 5000,
  warmup = 2000,
  chains = 4,
  thin = 3,
  seed = 123
)
```

```{r echo=FALSE}
# Resumen de los resultados
print(fit_combinado, pars = c("alpha", "beta"))
```

### Diagnóstico del modelo

```{r echo=FALSE}
# Extraer las muestras de la distribución posterior
posterior_samples_combinado <- extract(fit_combinado)
posterior_samples_combinado_2 <- extract(fit_combinado, inc_warmup = TRUE, permuted = FALSE)

# Cambiando el color para diferenciar del modelo anterior
color_scheme_set("purple")

mcmc_trace(
  posterior_samples_combinado_2, 
  pars = c("alpha", "beta"),
  n_warmup = 667, 
  facet_args = list(nrow = 2, labeller = label_parsed)
) + theme_minimal() + facet_text(size = 12)

muestra_promedios_ergodicos(posterior_samples_combinado_2, color_palette = "Purples")
```

### Posterior de $\alpha$ y $\beta$

A continuación, visualizamos los muestras de las posteriores de $\alpha$ y $\beta$ con el modelo bayesiano incluyendo los 12 estudios adicionales. Se aprecia que $\alpha$ se diferencia de $\beta$ volviéndose más negativo que en el resultado de `Stan` anterior, siendo aquí $E[\alpha|x]\approx-1.635$

```{r echo=FALSE, warning=FALSE, message=FALSE}
mcmc_areas(fit_combinado, pars = c("alpha", "beta"), prob = 0.95) + 
  theme_minimal() +
  labs(
    title = expression(paste("Distribuciones posteriores de ", alpha, " y ", beta, " para el modelo combinado")),
    subtitle = "Con medianas e intervalos de credibilidad de 95%"
  ) +
  geom_vline(xintercept = 0, linetype = "dashed")

# beta_samples <- posterior_samples_combinado$beta
# sum(beta_samples < 0) / length(beta_samples)
```

#### Intervalo de credibilidad

De la gráfica anterior es fácil calcular el intervalo de credibilidad o high density interval (HDI por sus siglas en inglés).

$$
P[-0.859 \leq\beta\leq0.0226] \approx 0.95
$$

#### Planteamiento de hipótesis

Podemos plantear una hipótesis sobre la probabilidad de $\beta$ como lo hicimos en la pregunta anterior. Si las investigadoras se plantearan si existe una relación negativa entre el nivel de dosis y la probabilidad de presentar el tumor para una rata, tendrían que calcular:

$$
H_0: \beta < 0 \quad \text{vs} \quad H_a: \beta \geq 0
$$

desde el enfoque bayesiano, esto equivaldría a calcular la plausibilidad de que la $\beta$ sea negativa.

Con este modelo propuesto, observamos que: $p(\beta<0) \approx 0.9665$

### Curvas de ajuste del modelo

```{r echo=FALSE}
grafica_ajuste_curva(posterior_samples_combinado, "alpha", "beta")
```

\clearpage

# Ejercicio 3: Modelo Jerárquico

Poco tiempo después, una de las investigadoras tuvo la oportunidad de asistir a un curso de Análisis Bayesiano de Modelos Jerárquicos y convenció al resto del equipo de que ésa es la manera más apropiada de analizar los datos con los que contaban. Específicamente, dado que todos los estudios eran similares, consideraron que podían utilizar los 12 estudios que encontraron en la literatura para complementar la información de su experimento original (ver Tabla 1).

Las investigadoras supusieron entonces que los parámetros ${\alpha_1,\alpha_2,...,\alpha_{12}}$ eran intercambiables, con distribución común $N(\alpha^*,\sigma^2_\alpha)$, y también que los parámetros 
$\beta,\beta_{11},\beta_{12}$ eran intercambiables con distribución común $N(\beta^*,\sigma^2_\beta)$. Finalmente, tanto para $\alpha^*$ como para $\beta^*$ supusieron una distribución $N(0,100)$, mientras que para $\tau_\alpha=1/\sigma^2_\alpha$ y $\tau_\beta=1/\sigma^2_\beta$ consideraron una distribución $Gamma(0.01,0.01)$.

Se propone un resumen de la distribución final de $\beta$ (la correspondiente al Ejercicio 1) bajo estas condiciones.

\clearpage

## Respuesta

### Definiendo el modelo en `Stan`

```{r}
model_string_3 <- "
data {
  int<lower=0> N1; 
  int<lower=0> n1[N1];  
  int<lower=0> y1[N1];  
  vector[N1] x1;        

  int<lower=0> N0;      
  int<lower=0> n0[N0];  
  int<lower=0> y0[N0];  

  int<lower=0> N11;     
  int<lower=0> n11[N11];
  int<lower=0> y11[N11];
  vector[N11] x11;      

  int<lower=0> N12;     
  int<lower=0> n12[N12];
  int<lower=0> y12[N12];
  vector[N12] x12;      
}

parameters {
  real alpha_estrella;        
  real<lower=0> tau_alpha;
  vector[12] alpha;  

  real beta_estrella;         
  real<lower=0> tau_beta; 
  real beta;              
  real beta_11;           
  real beta_12;           
}

transformed parameters {
  real sigma_alpha = 1 / sqrt(tau_alpha); 
  real sigma_beta = 1 / sqrt(tau_beta);
}

model {
  alpha_estrella ~ normal(0, 10);
  beta_estrella ~ normal(0, 10);
  tau_alpha ~ gamma(0.01, 0.01);
  tau_beta ~ gamma(0.01, 0.01);

  alpha ~ normal(alpha_estrella, sigma_alpha);
  beta ~ normal(beta_estrella, sigma_beta);
  beta_11 ~ normal(beta_estrella, sigma_beta);
  beta_12 ~ normal(beta_estrella, sigma_beta);

  for (i in 1:N1) {
    y1[i] ~ binomial_logit(n1[i], alpha[1] + beta * x1[i]);
  }

  for (i in 1:N0) {
    y0[i] ~ binomial_logit(n0[i], alpha[i+1]);
  }

  for (i in 1:N11) {
    y11[i] ~ binomial_logit(n11[i], alpha[11] + beta_11 * x11[i]);
  }

  for (i in 1:N12) {
    y12[i] ~ binomial_logit(n12[i], alpha[12] + beta_12 * x12[i]);
  }
}
"
```

```{r echo=FALSE}
# Datos del experimento original (Tabla 1)
x_1 <- c(0, 1, 2)
n_x_1 <- c(14, 34, 34)
y_x_1 <- c(4, 4, 2)

# Datos de los estudios de control (Tabla 2a)
n_0 <- c(10, 13, 48, 19, 20, 18, 25, 49, 48, 19)
y_0 <- c(1, 2, 10, 5, 0, 0, 2, 5, 9, 4)

# Datos de los estudios 11 (Tabla 2b)
x_11 <- c(0, 1, 2)
n_x_11 <- c(7, 16, 18)
y_x_11 <- c(3, 5, 2)

# Datos de los estudios 12 (Tabla 2c)
x_12 <- c(0, 1, 2)
n_x_12 <- c(5, 11, 9)
y_x_12 <- c(2, 1, 0)

modelo_jerarquico <- stan_model(model_code = model_string_3)
```

```{r echo=FALSE, error=FALSE, message=FALSE, results=FALSE}
data_jerarquico <- list(
  # Estudios original
  N1 = length(x_1), n1 = n_x_1, y1 = y_x_1, x1 = x_1,
  
  # Estudios de ceros
  N0 = length(n_0), n0 = n_0, y0 = y_0,
  
  # Estudios 11
  N11 = length(x_11), n11 = n_x_11, y11 = y_x_11, x11 = x_11,
  
  # Estudio 12
  N12 = length(x_12), n12 = n_x_12, y12 = y_x_12, x12 = x_12
)

fit_jerarquico <- sampling(
  object = modelo_jerarquico,
  data = data_jerarquico,
  iter = 5000,
  warmup = 2000,
  chains = 4,
  thin = 3,
  seed = 123
)
```

### Diagnósticos del modelo

```{r echo=FALSE}
color_scheme_set("green")

posterior_jerarquico <- extract(fit_jerarquico)
posterior_jerarquico_2 <- extract(fit_jerarquico, inc_warmup = TRUE, permuted = FALSE)

mcmc_trace(
  posterior_jerarquico_2, 
  pars = c("beta", "beta_11", "beta_12"),
  n_warmup = 667, 
  facet_args = list(nrow = 2, labeller = label_parsed)
) + theme_minimal() + facet_text(size = 12)

```

### Posteriores de las $\beta$'s

```{r echo=FALSE, message=FALSE, warning=FALSE}
mcmc_areas(
  fit_jerarquico, pars = c("beta", "beta_11", "beta_12"), prob = 0.95
) + geom_vline(xintercept = 0, linetype = "dashed") + theme_minimal()
```

# Ejercicio 4: Modelos

## Comparación de modelos

## Discusión de resultados

\clearpage
# Comentarios finales
\clearpage
# Referencias

\begin{itemize}

    \item Martín de Civetta MT y  Civetta JD.(2011). Carcinogénesis. Salúd Pública Mex;53:405-414.

\end{itemize}
